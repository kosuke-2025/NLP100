{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "X5YgWh7ldCR4",
        "tags": []
      },
      "source": [
        "# 第7章: 機械学習\n",
        "\n",
        "本章では、[Stanford Sentiment Treebank (SST)](https://nlp.stanford.edu/sentiment/) データセットを用い、評判分析器（ポジネガ分類器）を構築する。ここでは処理を簡略化するため、[General Language Understanding Evaluation (GLUE)](https://gluebenchmark.com/) ベンチマークで配布されているSSTデータセットを用いる。\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\n",
        "!unzip SST-2.zip"
      ],
      "metadata": {
        "id": "k0kpTwoM3ZCh",
        "outputId": "856240e0-045f-4197-8788-33a5cf1b487f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-12 05:04:51--  https://dl.fbaipublicfiles.com/glue/data/SST-2.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.238.176.19, 18.238.176.126, 18.238.176.115, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.238.176.19|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7439277 (7.1M) [application/zip]\n",
            "Saving to: ‘SST-2.zip’\n",
            "\n",
            "SST-2.zip           100%[===================>]   7.09M  37.3MB/s    in 0.2s    \n",
            "\n",
            "2025-05-12 05:04:52 (37.3 MB/s) - ‘SST-2.zip’ saved [7439277/7439277]\n",
            "\n",
            "Archive:  SST-2.zip\n",
            "   creating: SST-2/\n",
            "  inflating: SST-2/dev.tsv           \n",
            "   creating: SST-2/original/\n",
            "  inflating: SST-2/original/README.txt  \n",
            "  inflating: SST-2/original/SOStr.txt  \n",
            "  inflating: SST-2/original/STree.txt  \n",
            "  inflating: SST-2/original/datasetSentences.txt  \n",
            "  inflating: SST-2/original/datasetSplit.txt  \n",
            "  inflating: SST-2/original/dictionary.txt  \n",
            "  inflating: SST-2/original/original_rt_snippets.txt  \n",
            "  inflating: SST-2/original/sentiment_labels.txt  \n",
            "  inflating: SST-2/test.tsv          \n",
            "  inflating: SST-2/train.tsv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaAFO9l2fE19"
      },
      "source": [
        "## 60. データの入手・整形\n",
        "\n",
        "GLUEのウェブサイトから[SST-2](https://dl.fbaipublicfiles.com/glue/data/SST-2.zip)データセットを取得せよ。学習データ（`train.tsv`）と検証データ（`dev.tsv`）のぞれぞれについて、ポジティブ (1) とネガティブ (0) の事例数をカウントせよ。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train=pd.read_csv(\"/content/SST-2/train.tsv\",sep=\"\\t\")\n",
        "dev=pd.read_csv(\"/content/SST-2/dev.tsv\",sep=\"\\t\")\n",
        "\n",
        "print(f\"学習データ:\\n{train['label'].value_counts()}\\n\")\n",
        "print(f\"検証データ:\\n{dev['label'].value_counts()}\")"
      ],
      "metadata": {
        "id": "-SoojgB_0yY_",
        "outputId": "f1ece584-ab92-45ac-ed07-d522271c4ac8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "学習データ:\n",
            "label\n",
            "1    37569\n",
            "0    29780\n",
            "Name: count, dtype: int64\n",
            "\n",
            "検証データ:\n",
            "label\n",
            "1    444\n",
            "0    428\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EY71AIPgmJF"
      },
      "source": [
        "## 61. 特徴ベクトル\n",
        "\n",
        "Bag of Words (BoW) に基づき、学習データ（`train.tsv`）および検証データ（`dev.tsv`）のテキストを特徴ベクトルに変換したい。ここで、ある事例のテキストの特徴ベクトルは、テキスト中に含まれる単語（スペース区切りのトークン）の出現頻度で構成する。例えば、\"too loud , too goofy\"というテキストに対応する特徴ベクトルは、以下のような辞書オブジェクトで表現される。\n",
        "\n",
        "```python\n",
        "{'too': 2, 'loud': 1, ',': 1, 'goofy': 1}\n",
        "```\n",
        "\n",
        "各事例はテキスト、特徴ベクトル、ラベルを格納した辞書オブジェクトでまとめておく。例えば、先ほどの\"too loud , too goofy\"に対してラベル\"0\"（ネガティブ）が付与された事例は、以下のオブジェクトで表現される。\n",
        "\n",
        "```python\n",
        "{'text': 'too loud , too goofy', 'label': '0', 'feature': {'too': 2, 'loud': 1, ',': 1, 'goofy': 1}}\n",
        "```\n",
        "\n",
        "学習データと検証データの各事例を上記のような辞書オブジェクトに変換したうえで、学習データと検証データのそれぞれを、辞書オブジェクトのリストとして表現せよ。さらに、学習データの最初の事例について、正しく特徴ベクトルに変換できたか、目視で確認せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i40n9yZnCsv"
      },
      "source": [
        "## 62. 学習\n",
        "\n",
        "61で構築した学習データの特徴ベクトルを用いて、ロジスティック回帰モデルを学習せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wuvGIAonZEF"
      },
      "source": [
        "## 63. 予測\n",
        "\n",
        "学習したロジスティック回帰モデルを用い、検証データの先頭の事例のラベル（ポジネガ）を予測せよ。また、予測されたラベルが検証データで付与されていたラベルと一致しているか、確認せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "ZHZht1jNoJPL",
        "tags": []
      },
      "source": [
        "## 64. 条件付き確率\n",
        "\n",
        "学習したロジスティック回帰モデルを用い、検証データの先頭の事例を各ラベル（ポジネガ）に分類するときの条件付き確率を求めよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "sa4FRl8kos_0",
        "tags": []
      },
      "source": [
        "## 65. テキストのポジネガの予測\n",
        "\n",
        "与えられたテキストのポジネガを予測するプログラムを実装せよ。例えば、テキストとして\"the worst movie I 've ever seen\"を与え、ロジスティック回帰モデルの予測結果を確認せよ。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "JpIsH36Upci_",
        "tags": []
      },
      "source": [
        "## 66. 混同行列の作成\n",
        "\n",
        "学習したロジスティック回帰モデルの検証データにおける混同行列（confusion matrix）を求めよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "editable": true,
        "id": "wVGFDz94oaqV",
        "tags": []
      },
      "source": [
        "## 67. 精度の計測\n",
        "\n",
        "学習したロジスティック回帰モデルの正解率、適合率、再現率、F1スコアを、学習データおよび検証データ上で計測せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N14sd55qq-xS"
      },
      "source": [
        "## 68. 特徴量の重みの確認\n",
        "\n",
        "学習したロジスティック回帰モデルの中で、重みの高い特徴量トップ20と、重みの低い特徴量トップ20を確認せよ。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiEXYV__rJYR"
      },
      "source": [
        "## 69. 正則化パラメータの変更\n",
        "\n",
        "ロジスティック回帰モデルを学習するとき、正則化の係数（ハイパーパラメータ）を調整することで、学習時の適合度合いを制御できる。正則化の係数を変化させながらロジスティック回帰モデルを学習し、検証データ上の正解率を求めよ。実験の結果は、正則化パラメータを横軸、正解率を縦軸としたグラフにまとめよ。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}